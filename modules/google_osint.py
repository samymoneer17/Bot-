"""
Google OSINT Module - Ù…Ø³ØªÙˆØ­Ù‰ Ù…Ù† GHunt
Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ­Ù‚ÙŠÙ‚ ÙÙŠ Ø­Ø³Ø§Ø¨Ø§Øª Google
"""

import aiohttp
from aiohttp import ClientTimeout
import asyncio
import re
import os
from dotenv import load_dotenv
import json

load_dotenv()

RAPIDAPI_KEY = os.getenv("RAPIDAPI_KEY")


async def google_email_osint(email: str) -> str:
    """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­Ø³Ø§Ø¨ Google Ù…Ù† Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„"""
    
    email_regex = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$'
    if not re.match(email_regex, email):
        return "âŒ ØµÙŠØºØ© Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ØºÙŠØ± ØµØ­ÙŠØ­Ø©"
    
    text = f"ğŸ” *ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø§Ø¨ Google*\n\n"
    text += f"ğŸ“§ *Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„:* `{email}`\n\n"
    
    is_gmail = email.lower().endswith('@gmail.com')
    text += f"ğŸ“Œ *Ù†ÙˆØ¹ Ø§Ù„Ø­Ø³Ø§Ø¨:* {'Gmail' if is_gmail else 'Google Workspace / Ø­Ø³Ø§Ø¨ Ø¢Ø®Ø±'}\n"
    
    if is_gmail:
        username = email.split('@')[0]
        text += f"ğŸ‘¤ *Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:* `{username}`\n"
        
        dot_variations = []
        clean_username = username.replace('.', '')
        text += f"ğŸ”„ *Ø§Ù„Ø§Ø³Ù… Ø¨Ø¯ÙˆÙ† Ù†Ù‚Ø§Ø·:* `{clean_username}@gmail.com`\n"
        
        plus_example = f"{username}+anything@gmail.com"
        text += f"â• *Ù…Ø«Ø§Ù„ Plus addressing:* `{plus_example}`\n"
    
    text += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    text += "ğŸ”— *Ø±ÙˆØ§Ø¨Ø· Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø­Ø³Ø§Ø¨:*\n\n"
    
    if is_gmail:
        username = email.split('@')[0].replace('.', '')
        text += f"ğŸ“º *YouTube:* https://www.youtube.com/@{username}\n"
        text += f"ğŸ“¸ *Google Photos:* (ÙŠØªØ·Ù„Ø¨ Ø±Ø§Ø¨Ø· Ù…Ø´ØªØ±Ùƒ)\n"
        text += f"ğŸ—ºï¸ *Google Maps:* https://www.google.com/maps/contrib/\n"
        text += f"ğŸ“ *Blogger:* https://{username}.blogspot.com\n"
    
    text += f"\nğŸ” *Google Search:* https://www.google.com/search?q=\"{email}\"\n"
    
    text += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    text += "â„¹ï¸ *Ù…Ù„Ø§Ø­Ø¸Ø©:* Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø¹Ù…Ù‚ Ù…Ø«Ù„ GAIA ID ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©ØŒ\n"
    text += "ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯Ø§Ø© GHunt Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ:\n"
    text += "`ghunt email " + email + "`"
    
    return text


async def youtube_channel_osint(channel_input: str) -> str:
    """ØªØ­Ù„ÙŠÙ„ Ù‚Ù†Ø§Ø© ÙŠÙˆØªÙŠÙˆØ¨ - Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù‚Ù†Ø§Ø©"""
    
    if not RAPIDAPI_KEY:
        return "âŒ Ù…ÙØªØ§Ø­ RapidAPI ØºÙŠØ± Ù…ØªÙˆÙØ±\nÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØ© RAPIDAPI_KEY ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"
    
    channel_id = None
    username = None
    
    if 'youtube.com' in channel_input or 'youtu.be' in channel_input:
        if '/channel/' in channel_input:
            match = re.search(r'/channel/([a-zA-Z0-9_-]+)', channel_input)
            if match:
                channel_id = match.group(1)
        elif '/@' in channel_input:
            match = re.search(r'/@([a-zA-Z0-9_-]+)', channel_input)
            if match:
                username = match.group(1)
        elif '/user/' in channel_input:
            match = re.search(r'/user/([a-zA-Z0-9_-]+)', channel_input)
            if match:
                username = match.group(1)
        elif '/c/' in channel_input:
            match = re.search(r'/c/([a-zA-Z0-9_-]+)', channel_input)
            if match:
                username = match.group(1)
    else:
        if channel_input.startswith('UC') and len(channel_input) == 24:
            channel_id = channel_input
        else:
            username = channel_input
    
    api_host = "youtube-v31.p.rapidapi.com"
    headers = {
        "x-rapidapi-key": RAPIDAPI_KEY,
        "x-rapidapi-host": api_host
    }
    
    try:
        async with aiohttp.ClientSession() as session:
            if channel_id:
                url = f"https://{api_host}/channels"
                params = {"part": "snippet,statistics,brandingSettings", "id": channel_id}
            else:
                url = f"https://{api_host}/search"
                params = {"q": username, "part": "snippet", "type": "channel", "maxResults": 1}
            
            async with session.get(url, headers=headers, params=params, timeout=ClientTimeout(total=30)) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    items = data.get('items', [])
                    if not items:
                        return f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‚Ù†Ø§Ø©: `{channel_input}`"
                    
                    if not channel_id:
                        channel_id = items[0].get('snippet', {}).get('channelId') or items[0].get('id', {}).get('channelId')
                        
                        url = f"https://{api_host}/channels"
                        params = {"part": "snippet,statistics,brandingSettings", "id": channel_id}
                        
                        async with session.get(url, headers=headers, params=params, timeout=ClientTimeout(total=30)) as resp2:
                            if resp2.status == 200:
                                data = await resp2.json()
                                items = data.get('items', [])
                    
                    if items:
                        channel = items[0]
                        snippet = channel.get('snippet', {})
                        stats = channel.get('statistics', {})
                        branding = channel.get('brandingSettings', {}).get('channel', {})
                        
                        text = f"ğŸ“º *ØªØ­Ù„ÙŠÙ„ Ù‚Ù†Ø§Ø© YouTube*\n\n"
                        text += f"ğŸ†” *Channel ID:* `{channel.get('id', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}`\n"
                        text += f"ğŸ“› *Ø§Ø³Ù… Ø§Ù„Ù‚Ù†Ø§Ø©:* {snippet.get('title', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}\n"
                        
                        if snippet.get('customUrl'):
                            text += f"ğŸ”— *Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø®ØµØµ:* youtube.com/{snippet.get('customUrl')}\n"
                        
                        text += f"\nğŸ“Š *Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:*\n"
                        text += f"  ğŸ‘¥ Ø§Ù„Ù…Ø´ØªØ±ÙƒÙŠÙ†: {format_number(stats.get('subscriberCount', 0))}\n"
                        text += f"  ğŸ“¹ Ø¹Ø¯Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª: {format_number(stats.get('videoCount', 0))}\n"
                        text += f"  ğŸ‘ï¸ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø§Øª: {format_number(stats.get('viewCount', 0))}\n"
                        
                        if snippet.get('publishedAt'):
                            created = snippet.get('publishedAt', '')[:10]
                            text += f"\nğŸ“… *ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡:* {created}\n"
                        
                        if snippet.get('country'):
                            text += f"ğŸŒ *Ø§Ù„Ø¨Ù„Ø¯:* {snippet.get('country')}\n"
                        
                        if snippet.get('description'):
                            desc = snippet.get('description', '')[:200]
                            text += f"\nğŸ“ *Ø§Ù„ÙˆØµÙ:*\n{desc}...\n"
                        
                        if branding.get('keywords'):
                            text += f"\nğŸ·ï¸ *Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©:* {branding.get('keywords')[:100]}...\n"
                        
                        text += f"\nğŸ”— *Ø±Ø§Ø¨Ø· Ø§Ù„Ù‚Ù†Ø§Ø©:*\nhttps://www.youtube.com/channel/{channel.get('id')}"
                        
                        return text
                    else:
                        return f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù‚Ù†Ø§Ø©"
                else:
                    return f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {response.status}"
                    
    except asyncio.TimeoutError:
        return "âŒ Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„"
    except Exception as e:
        return f"âŒ Ø®Ø·Ø£: {str(e)}"


async def google_drive_osint(drive_url: str) -> str:
    """ØªØ­Ù„ÙŠÙ„ Ø±Ø§Ø¨Ø· Google Drive Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©"""
    
    file_id = None
    
    patterns = [
        r'/file/d/([a-zA-Z0-9_-]+)',
        r'/document/d/([a-zA-Z0-9_-]+)',
        r'/spreadsheets/d/([a-zA-Z0-9_-]+)',
        r'/presentation/d/([a-zA-Z0-9_-]+)',
        r'/folders/([a-zA-Z0-9_-]+)',
        r'id=([a-zA-Z0-9_-]+)',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, drive_url)
        if match:
            file_id = match.group(1)
            break
    
    if not file_id:
        if len(drive_url) > 20 and re.match(r'^[a-zA-Z0-9_-]+$', drive_url):
            file_id = drive_url
        else:
            return "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Google Drive\nÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ø§Ø¨Ø· ØµØ§Ù„Ø­"
    
    text = f"ğŸ“ *ØªØ­Ù„ÙŠÙ„ Ø±Ø§Ø¨Ø· Google Drive*\n\n"
    text += f"ğŸ†” *File/Folder ID:* `{file_id}`\n\n"
    
    if '/document/' in drive_url or 'docs.google.com' in drive_url:
        file_type = "ğŸ“„ Google Docs"
    elif '/spreadsheets/' in drive_url or 'sheets.google.com' in drive_url:
        file_type = "ğŸ“Š Google Sheets"
    elif '/presentation/' in drive_url or 'slides.google.com' in drive_url:
        file_type = "ğŸ“½ï¸ Google Slides"
    elif '/folders/' in drive_url:
        file_type = "ğŸ“‚ Google Drive Folder"
    elif '/file/' in drive_url:
        file_type = "ğŸ“ Google Drive File"
    else:
        file_type = "ğŸ“ Google Drive Item"
    
    text += f"ğŸ“Œ *Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù:* {file_type}\n\n"
    
    text += "ğŸ”— *Ø±ÙˆØ§Ø¨Ø· Ù…ÙÙŠØ¯Ø©:*\n"
    text += f"  â€¢ *Ø¹Ø±Ø¶:* https://drive.google.com/file/d/{file_id}/view\n"
    text += f"  â€¢ *ØªØ­Ù…ÙŠÙ„:* https://drive.google.com/uc?id={file_id}&export=download\n"
    text += f"  â€¢ *Ù…Ø¹Ø§ÙŠÙ†Ø©:* https://drive.google.com/file/d/{file_id}/preview\n"
    
    text += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    text += "â„¹ï¸ *Ù…Ù„Ø§Ø­Ø¸Ø©:* Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø§Ù„Ùƒ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©ØŒ\n"
    text += "Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø¯Ø§Ø© GHunt Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ:\n"
    text += f"`ghunt drive {drive_url}`"
    
    return text


async def wifi_geolocate(bssid: str) -> str:
    """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠ Ù…Ù† BSSID Ø§Ù„Ø®Ø§Øµ Ø¨Ø´Ø¨ÙƒØ© WiFi"""
    
    bssid = bssid.upper().replace('-', ':')
    
    bssid_regex = r'^([0-9A-F]{2}:){5}[0-9A-F]{2}$'
    if not re.match(bssid_regex, bssid):
        return "âŒ ØµÙŠØºØ© BSSID ØºÙŠØ± ØµØ­ÙŠØ­Ø©\nØ§Ù„ØµÙŠØºØ© Ø§Ù„ØµØ­ÙŠØ­Ø©: XX:XX:XX:XX:XX:XX"
    
    text = f"ğŸ“¡ *ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆÙ‚Ø¹ WiFi*\n\n"
    text += f"ğŸ” *BSSID:* `{bssid}`\n\n"
    
    vendor_prefix = bssid[:8]
    text += f"ğŸ­ *Vendor Prefix:* `{vendor_prefix}`\n"
    
    text += "\nğŸ”— *Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹:*\n\n"
    text += f"1ï¸âƒ£ *WiGLE:*\nhttps://wigle.net/search?netid={bssid}\n\n"
    text += f"2ï¸âƒ£ *OpenWiFiMap:*\nhttps://openwifimap.net/\n\n"
    text += f"3ï¸âƒ£ *MAC Vendor Lookup:*\nhttps://macvendors.com/?q={vendor_prefix}\n\n"
    
    text += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    text += "â„¹ï¸ *Ù…Ù„Ø§Ø­Ø¸Ø©:* Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Google APIØŒ\n"
    text += "Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø¯Ø§Ø© GHunt Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ:\n"
    text += f"`ghunt geolocate {bssid}`"
    
    return text


async def google_search_dork(query: str, dork_type: str = "general") -> str:
    """Ø¨Ø­Ø« Google Ø§Ù„Ù…ØªÙ‚Ø¯Ù… (Google Dorking)"""
    
    dorks = {
        "email": f'"{query}" site:linkedin.com OR site:facebook.com OR site:twitter.com',
        "documents": f'"{query}" filetype:pdf OR filetype:doc OR filetype:xls',
        "social": f'"{query}" site:facebook.com OR site:instagram.com OR site:twitter.com OR site:linkedin.com',
        "leaks": f'"{query}" site:pastebin.com OR site:ghostbin.com OR site:hastebin.com',
        "general": f'"{query}"'
    }
    
    search_query = dorks.get(dork_type, dorks["general"])
    encoded_query = search_query.replace(' ', '+').replace('"', '%22')
    
    text = f"ğŸ” *Google Dorking*\n\n"
    text += f"ğŸ¯ *Ø§Ù„Ù‡Ø¯Ù:* `{query}`\n"
    text += f"ğŸ“‚ *Ù†ÙˆØ¹ Ø§Ù„Ø¨Ø­Ø«:* {dork_type}\n\n"
    
    text += "ğŸ”— *Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¨Ø­Ø«:*\n\n"
    
    text += f"1ï¸âƒ£ *Ø¨Ø­Ø« Ø¹Ø§Ù…:*\nhttps://www.google.com/search?q=\"{query}\"\n\n"
    text += f"2ï¸âƒ£ *Ø¨Ø­Ø« Ø§Ù„ØµÙˆØ±:*\nhttps://www.google.com/search?tbm=isch&q=\"{query}\"\n\n"
    text += f"3ï¸âƒ£ *Ø¨Ø­Ø« Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª:*\nhttps://www.google.com/search?q=\"{query}\"+filetype:pdf+OR+filetype:doc\n\n"
    text += f"4ï¸âƒ£ *Ø§Ù„Ø³ÙˆØ´ÙŠØ§Ù„ Ù…ÙŠØ¯ÙŠØ§:*\nhttps://www.google.com/search?q=\"{query}\"+site:linkedin.com+OR+site:facebook.com\n\n"
    text += f"5ï¸âƒ£ *Ø§Ù„ØªØ³Ø±ÙŠØ¨Ø§Øª:*\nhttps://www.google.com/search?q=\"{query}\"+site:pastebin.com\n\n"
    
    text += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    text += "ğŸ’¡ *Ù†ØµØ§Ø¦Ø­ Google Dorking:*\n"
    text += "â€¢ `site:` Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ù…ÙˆÙ‚Ø¹ Ù…Ø­Ø¯Ø¯\n"
    text += "â€¢ `filetype:` Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†ÙˆØ¹ Ù…Ù„Ù\n"
    text += "â€¢ `inurl:` Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·\n"
    text += "â€¢ `intitle:` Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„ØµÙØ­Ø§Øª"
    
    return text


def format_number(num):
    """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ÙƒØ¨ÙŠØ±Ø©"""
    try:
        num = int(num)
        if num >= 1000000000:
            return f"{num/1000000000:.1f}B"
        elif num >= 1000000:
            return f"{num/1000000:.1f}M"
        elif num >= 1000:
            return f"{num/1000:.1f}K"
        return str(num)
    except:
        return str(num)
